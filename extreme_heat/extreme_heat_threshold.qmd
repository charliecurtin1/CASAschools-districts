---
title: "Calculating a threshold value for extreme heat"
format: html
author: "Charlie Curtin"
---

```{r, message = FALSE}
# load libraries
library(devtools)
library(caladaptr)
library(tidyverse)
library(sf)
library(here)
library(progress) # for loop progress bar

# install caladaptr to construct an API request for climate data from Cal-Adapt
#devtools::install_github("ucanr-igis/caladaptr")
```

## Request daily maximum temperature for California school districts

To describe extreme heat, we first need a value for extreme heat, or a temperature above which a day is considered an extreme heat day. The method we use for this analysis is to calculate the 98th percentile value of observed maximum daily temperature. The 98th percentile value is calculated for every school district and then averaged across all districts to define a final extreme heat threshold. We are going to begin by requesting daily maximum temperature for every California school district from 1961-1990, considered our baseline historical time period. This timeline is based on the Cal-Adapt extreme heat tool: https://cal-adapt.org/tools/extreme-heat/. To achieve this, the for loop in this notebook takes school district polygons one-by-one. Daily maximum temperature is requested for each day between 1961-1990, and then the 98th percentile of those values calculated. The for loop iterates over each polygon and builds a table of 98th percentile values. The for loop also stores the CDSCodes (unique IDs) of schools that encounter an error.

```{r}
# read in school districts, validate geometry, and change the crs to WGS 1984
districts <- st_read(here("data", "school_districts"), quiet = TRUE) %>% 
  st_make_valid() %>% 
  st_transform(crs = 4326)
```

## Data retrieval

```{r}
# create an empty data frame to populate with percentiles
pct_98_temp <- data.frame()

# create an empty vector to store the codes of districts that encounter an error
temp_errors <- c()

# create a progress bar for our for loop
pb <- progress_bar$new(
  format = "  [:bar] :current/:total (:percent) elapsed: :elapsed full",
  total = nrow(districts), clear = FALSE, width = 60
)

# create a for loop for school districts
for (code in districts$CDSCode) {
   
  # iterate through one row at a time
  df <- districts %>% 
    filter(CDSCode == code)
  
  # wrap process in tryCatch function to continue iterating if the for loop encounters an error
  tryCatch({
    # create the request, where "df" contains the simple features for our locations, and we use "CDSCode" as the unique identifier
    request <-  ca_loc_sf(loc = df, idfld = "CDSCode") %>% 
      # select our variable of interest, where "tasmax" is maximum temperature
      ca_cvar(cvar = "tasmax") %>% 
      # select the dataset we retrieve from, where Livneh is the historical climate observations
      ca_livneh(TRUE) %>% 
      # select daily values
      ca_period("day") %>% 
      # select period of interest
      ca_years(start = 1961, end = 1990)
    
    # calculate the 98th percentile for each school district based on retrieved data
    districts_temp <- request %>% 
      # extract values from request as a table, converting values to be numeric
      ca_getvals_tbl(quiet = TRUE) %>%
      mutate(val = as.numeric(val)) %>% 
      # calculate 98th percentile for each district
      summarize(pct_98 = quantile(val, probs = 0.98))
    
    # repopulate the district name field
    districts_temp$CDSCode <- code
    
    # bind results from each iteration to the dataframe we defined outside of the for loop
    pct_98_temp <- rbind(pct_98_temp, districts_temp)
    
    },
    error = function(e) {
      # store the district code in error_districts if there's an error
      temp_errors <<- c(temp_errors, code)
    })
  
  # update progress bar
  pb$tick()
  
} # end for loop

# convert heat from C to F
pct_98_temp_noerror <- pct_98_temp %>% 
  mutate(pct_98 = pct_98 * (9 / 5) + 32)

# write results to data folder
#write_csv(pct_98_temp_noerror, here("data", "extreme_heat", "intermediate", "pct_98_temp_noerror.csv"))
```

## Working with errors

We need data for all school districts to make a proper estimate of a threshold for extreme heat. We encountered an error with 11 school districts. So, we are going to filter for the districts that are causing the error, generate 5 random points across their area, and feed those as locations into the API request. The process of calculating a 98th percentile looks largely the same, with the added step of averaging daily observations of the 5 points within each district before calculating a percentile. Results are in Celsius, so they must also be converted to Fahrenheit. The last step is to bind the two dataframes of percentiles (no errors and errors) and take the mean. That final value is the extreme heat threshold.

A limitation of taking the 5 random points is that multiple LOCA grid cells can cover one school district, so we might not be taking data from all available grid cells. You also get different results running it again based on where the sampled points land.

```{r}
# select the districts that encountered an error
error_districts <- districts %>% 
  filter(CDSCode %in% temp_errors)

# create an empty data frame to populate with percentiles
pct_98_temp_errors <- data.frame()

# create a progress bar for our for loop
pb <- progress_bar$new(
  format = "  [:bar] :current/:total (:percent) elapsed: :elapsed full",
  total = nrow(districts), clear = FALSE, width = 60
)

# create a for loop for school districts
for (code in error_districts$CDSCode) {
  
  # iterate through one row at a time
  df <- error_districts %>% 
    filter(CDSCode == code)
  
  # generate 5 random points for each district and convert to coordinates
  errors_points <- st_sample(error_districts, 5)
  
  errors_points <- st_transform(errors_points, crs = "EPSG:4326" ) %>% 
    st_coordinates()
  
  # API request
  tryCatch({
    # create the request using points instead of polygons as locations
    request <- ca_loc_pt(coords = errors_points) %>% 
      # select our variable of interest, where "tasmax" is maximum temperature
      ca_cvar(cvar = "tasmax") %>% 
      # select the dataset we retrieve from, where Livneh is the historical climate observations
      ca_livneh(TRUE) %>% 
      # select daily values
      ca_period("day") %>% 
      # select period of interest
      ca_years(start = 1961, end = 1990)
    
    # retrieve data and calculate 98th percentile for each district
    errors_thresh <- request %>%
      # extract values from request as a table and convert to be numeric
      ca_getvals_tbl(quiet = TRUE) %>% 
      mutate(val = as.numeric(val)) %>%
      # average the observations for all points within each district by grouping by date and taking a mean
      group_by(dt) %>% 
      summarize(val = mean(val)) %>% 
      # calculate the 98th percentile
      summarize(pct_98 = quantile(val, probs = 0.98))
    
    # assign CDSCode back to each percentile
    errors_thresh$CDSCode <- code
    
    # bind results from each iteration with the dataframe we defined outside of the for loop
    pct_98_temp_errors <- rbind(pct_98_temp_errors, errors_thresh)
  },
  error = function(e) {
  })
  
  # update progress bar
  pb$tick()
}

# convert temp from C to F
pct_98_temp_errors <- pct_98_temp_errors %>% 
  mutate(pct_98 = pct_98 * 9 / 5 + 32)

# export results to the data folder
#write_csv(pct_98_temp_errors, here("data", "extreme_heat", "intermediate", "pct_98_temp_errors"))

# rbind the error and noerror datasets together
pct_98_temp_full <- rbind(pct_98_temp_noerror, pct_98_temp_errors)

# export table to the data folder
write_csv(pct_98_temp_full, here("data", "extreme_heat", "intermediate", "pct_98_temp_full.csv"))

# calculate the threshold by finding the mean temp
threshold <- pct_98_temp_full %>% 
  summarise(mean = mean(pct_98))
```

So, we find our threshold for extreme heat to be 95.67 F.

