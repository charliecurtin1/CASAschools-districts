---
title: "Calculating total extreme precipitation days for all districts under RCP 8.5"
format: html
author: "Charlie Curtin"
---

```{r, message = FALSE}
# load libraries
library(devtools)
library(caladaptr)
library(tidyverse)
library(sf)
library(here)
library(progress) # for loop progress bar

# install caladaptr to construct an API request for climate data from Cal-Adapt
#devtools::install_github("ucanr-igis/caladaptr")

options(scipen = 999)
```

An extreme precipitation day is calculated as a day in which the daily total precipitation exceeds 0.74 inches. This threshold represents the 98th percentile value of total daily rainfall for California school districts based on observed precipitation data from 1961-1990. The threshold is calculated in `extreme_precip/extreme_precip_threshold.qmd`.

```{r}
# read in school districts, validate geometry, and change the crs to WGS 1984
districts <- st_read(here("data", "school_districts"), quiet = TRUE) %>% 
  st_make_valid() %>% 
  st_transform(crs = 4326)
```

# Determining the number of projected extreme precipitation days between 2030-2035 under RCP 8.5

To determine the number of projected extreme precipitation days for each district between 2030-2035 under RCP 8.5, we are going to retrieve daily projected total precipitation values from Cal-Adapt for each district for RCP 8.5 and 4 different GCMs that fit California's climate the best. The 4 GCMs represent 4 different future projected climate scenarios: a cool scenario, a warm scenario, an average scenario, and one least like the others to improve coverage over a range of values (Cal-Adapt). This process also uses a for loop that works similarly to the one that calculates the threshold value: iterating through one school district polygon at a time, retrieving daily projected total precipitation data, calculating total number of extreme precipitation days, and building a table row-by-row.

Since we retrieve data for 4 GCMs, each district has 4 separate daily records. Using an if else statement in the for loop, if any of those 4 records exceeds the extreme precipitation threshold, that day is considered an extreme precipitation day. Since the projected data comes in units of kg/m^2/s, we convert the threshold to in/day. Extreme precipitation days are assigned a 1. These are summed for every district to calculate the total number of projected extreme precipitation days.The data is retrieved using Cal-Adapt API, from the Pierce et al. (2018) dataset. 

```{r}
# create an empty data frame to populate with the number of extreme precipitation days
extreme_precip_days <- data.frame()

# create an empty vector to store the codes of districts that encounter an error
precip_errors <- c()

# create a progress bar for our for loop
pb <- progress_bar$new(
  format = "  [:bar] :current/:total (:percent) elapsed: :elapsed full",
  total = nrow(districts), clear = FALSE, width = 60
)

# create a for loop for school districts
for (code in districts$CDSCode) {
   
  # iterate through one row at a time
  df <- districts %>% 
    filter(CDSCode == code)
  
  # wrap in tryCatch function, which tells the for loop to continue iterating if it encounters an error
  tryCatch({
    # create the API request
    request <-  ca_loc_sf(loc = df, idfld = "CDSCode") %>% 
      # select our variable of interest, where "pr" is daily precipitation
      ca_cvar(cvar = "pr") %>% 
      # select RCP 8.5 scenario
      ca_scenario(c("rcp85")) %>% 
      # select 4 GCMs of interest
      ca_gcm(gcms[1:4]) %>% 
      # select daily values
      ca_period("day") %>% 
      # select period of interest
      ca_years(start = 2030, end = 2035)
    
    # calculate whether a day is an extreme precipitation day or not
    districts_precip <- request %>% 
      # extract values from request as a table, converting values to be numeric
      ca_getvals_tbl(quiet = TRUE) %>% 
      mutate(val = as.numeric(val)) %>%
      # convert from kg/m^2/s to in/day
      mutate(val = val * 3401.58) %>% 
      # assign a 1 to each daily value for each school district if ANY projected precipitation total from any of the 4 GCMs exceeds the threshold
      group_by(CDSCode, dt) %>% 
      summarize(threshold = ifelse(any(val > .74), 1, 0)) %>%
      # count the number of extreme precipitation days
      group_by(CDSCode) %>% 
      summarize(count = sum(threshold))
    
    extreme_precip_days <- rbind(extreme_precip_days, districts_precip)
    
    },
    error = function(e) {
      # store the district code in error_districts if there's an error
      precip_errors <<- c(precip_errors, code)
    })
  
  # update progress bar
  pb$tick()
  
} # end for loop

# export CSV
#write_csv(extreme_precip_days, here("data", "extreme_precip", "intermediate", "extreme_precip_days_noerrors.csv"))
```

## Working with errors for projected data

We encounter an error with 12 districts, meaning no data is retrieved for them, and the for loop skips the calculation. The process for working with errors involves filtering for them and generating 5 random points within their district boundary. These 5 points are fed into the for loop and the number of extreme heat days calculated in the same manner. An additional step is added to average daily observations for the 5 points for each GCM. After the districts that encounter an error are assigned a total number of projected extreme precipitation days, they are joined to the dataframe created above to create a table with the total number of projected extreme precipitation days for all 938 school districts.

```{r}
# filter for districts that encounter an error
error_districts <- districts %>% 
  filter(CDSCode %in% precip_errors$CDSCode)

# create an empty dataframe to populate with the number of extreme precip days
extreme_precip_days_errors <- data.frame()

# create a progress bar for our for loop
pb <- progress_bar$new(
  format = "  [:bar] :current/:total (:percent) elapsed: :elapsed full",
  total = nrow(districts), clear = FALSE, width = 60
)

# create a for loop for school districts
for (code in error_districts$CDSCode) {
   
  # iterate through one row at a time
  df <- error_districts %>% 
    filter(CDSCode == code)
  
  # generate 5 random points for each district and convert to coordinates
  errors_points <- st_sample(error_districts, 5)
  
  errors_points <- st_transform(errors_points, crs = "EPSG:4326" ) %>% 
  st_coordinates()
  
  # wrap in tryCatch function, which tells the for loop to continue iterating if it encounters an error
  tryCatch({
    # create the API request with points instead of polygons
    request <-  ca_loc_pt(coords = errors_points) %>% 
      ca_cvar(cvar = "pr") %>% 
      ca_scenario(c("rcp85")) %>% 
      ca_gcm(gcms[1:4]) %>% 
      ca_period("day") %>% 
      ca_years(start = 2030, end = 2035)
    
    # average the values of the 5 points for each district
    errors_precip <- request %>% 
      # extract values as a table, convert to be numeric, and convert to in/day
      ca_getvals_tbl(quiet = TRUE) %>% 
      mutate(val = as.numeric(val),
             val = val * 3401.58) %>% 
      # group by GCM and date to find the mean across all 5 points for each day
      group_by(gcm, dt) %>% 
      summarise(val = mean(val)) %>%
       # assign a 1 to each daily value for each school district if ANY projected precipitation total from any of the 4 GCMs exceeds the threshold
      group_by(dt) %>% 
      summarize(threshold = ifelse(any(val > .74), 1, 0)) %>% 
      # count the number of extreme precipitation days
      summarize(count = sum(threshold))
    
    # assign CDS code back to the point
    errors_precip$CDSCode <- code
    
    # bind results from each iteration together
    extreme_precip_days_errors <- rbind(extreme_precip_days_errors, errors_precip)
    
    },
    error = function(e) {
      # store the district code in error_districts if there's an error
      #precip_errors <<- c(precip_errors, code)
    })
  
  # update progress bar
  pb$tick()
  
} # end for loop

# write results to data folder
#write_csv(extreme_precip_days_errors, here("data", "extreme_precip", "intermediate", "extreme_precip_days_errors.csv"))
```

## Bind dataframes together and join back to full school districts data

```{r}
# bind the errors and noerrors dataframes together and export to data folder
extreme_precip_days_full <- rbind(extreme_precip_days_noerrors, extreme_precip_days_errors)

#write_csv(extreme_precip_days_full, here("data", "extreme_precip", "intermediate", "extreme_precip_days_full.csv"))

# join back to school districts dataframe
districts_precip <- left_join(districts, extreme_precip_days_full, by = "CDSCode") %>% 
  mutate(precip_days = count) %>% 
  select(CDSCode, CountyName, DistrictNa, DistrictTy, precip_days)

# export to data folder
write_csv(districts_precip, here("data", "hazard_summary", "individual_tables", "districts_precip.csv"))
```

# Determining the number of observed extreme precipitation days from 2008-2013

To provide a baseline for comparison, we are also going to calculate the number of observed extreme precipitation days from 2008-2013 using data retrieved from the Livneh et al. dataset. This is the same dataset used to calculate the extreme precipitation threshold. We use the same threshold value. Since these are observed data, there are not multiple daily observations under different GCMs, so the calculation is more simple. The data are also in units of millimeters, so the threshold is converted from 0.74 in to 18.8 mm.

```{r}
# create an empty data frame to populate with the number of extreme heat days
extreme_precip_days_hist <- data.frame()

# create an empty vector to store the codes of districts that encounter an error with the for loop
precip_errors <- c()

# create a progress bar for our for loop
pb <- progress_bar$new(
  format = "  [:bar] :current/:total (:percent) elapsed: :elapsed full",
  total = nrow(districts), clear = FALSE, width = 60
)

# retrieve data using the Cal-Adapt API in a for loop
for (code in districts$CDSCode) {
   
  # iterate through one row at a time
  df <- districts %>% 
    filter(CDSCode == code)
  
  # wrap in tryCatch function, which tells the for loop to continue iterating if it encounters an error
  tryCatch({
    # create the API request
    request <-  ca_loc_sf(loc = df, idfld = "CDSCode") %>% 
      # select our variable of interest, where "pr" is precipitation
      ca_cvar(cvar = "pr") %>% 
      # select the dataset we retrieve from, where Livneh is the historical climate observations
      ca_livneh(TRUE) %>% 
      # select daily values
      ca_period("day") %>% 
      # select period of interest
      ca_years(start = 2008, end = 2013)
    
    # calculate whether a day is an extreme precipitation day or not
    districts_precip <- request %>% 
      # extract values from request as a table, converting values to be numeric
      ca_getvals_tbl(quiet = TRUE) %>% 
      mutate(val = as.numeric(val)) %>% 
      # assign days a 1 if they exceed the threshold
      mutate(threshold = ifelse(val > 18.8, 1, 0)) %>% 
      # group by CDSCode and find the count of extreme precipitation days
      group_by(CDSCode) %>% 
      summarize(count = sum(threshold))
    
    # bind results from each iteration to our empty dataframe we defined outside of the for loop
    extreme_precip_days_hist <- rbind(extreme_precip_days_hist, districts_precip)
    
    },
    error = function(e) {
      # store the district code if there's an error
      precip_errors <<- c(precip_errors, code)
    })
  
  # update progress bar
  pb$tick()
  
} # end for loop

# export CSV
# write_csv(extreme_precip_days_hist, here("data", "extreme_precip", "intermediate", "extreme_precip_days_noerrors_hist.csv"))
```

## Working with errors

We encounter errors with 11 districts. We use the same process here, generating 5 random points within each district boundary to feed into the for loop. Then, we'll bind this dataframe with the one created above to generate a table with the observed total of extreme precipitation days from 2008-2013 for all 938 school districts.

```{r}
# filter for districts that encounter an error
error_districts <- districts %>% 
  filter(CDSCode %in% precip_errors)

# create an empty dataframe to populate with the number of extreme heat days
extreme_precip_days_errors_hist <- data.frame()

# create a progress bar for our for loop
pb <- progress_bar$new(
  format = "  [:bar] :current/:total (:percent) elapsed: :elapsed full",
  total = nrow(districts), clear = FALSE, width = 60
)

# create a for loop for school districts
for (code in error_districts$CDSCode) {
  
  # iterate through one row at a time
  df <- error_districts %>% 
    filter(CDSCode == code)
  
  # generate 5 random points for each district and convert to coordinates
  errors_points <- st_sample(error_districts, 5)
  
  errors_points <- st_transform(errors_points, crs = "EPSG:4326" ) %>% 
    st_coordinates()
  
  # wrap in tryCatch function, which tells the for loop to continue iterating if it encounters an error
  tryCatch({
    # create the API request
    request <- ca_loc_pt(coords = errors_points) %>% 
      # select our variable of interest, where "pr" is daily rainfall total
      ca_cvar(cvar = "pr") %>% 
      # select the dataset we retrieve from, where Livneh is the historical climate observations
      ca_livneh(TRUE) %>% 
      # select daily values
      ca_period("day") %>% 
      # select period of interest
      ca_years(start = 2008, end = 2013)
    
     # average the values of the 5 points for each district and determine whether a day is an extreme precipitation day
    errors_precip <- request %>% 
      # extract values from request as a table, converting values to be numeric
      ca_getvals_tbl(quiet = TRUE) %>% 
      mutate(val = as.numeric(val)) %>% 
      # group by date and find the mean of each of the 5 daily observations
      group_by(dt) %>% 
      summarise(val = mean(val)) %>% 
      # assign days a 1 if they exceed the threshold
      mutate(threshold = ifelse(val > 18.8, 1, 0)) %>% 
      # count the number of extreme precipitation days
      summarize(count = sum(threshold))
    
    # assign CDSCode back to the point
    errors_precip$CDSCode <- code
    
    # bind results from each iteration together
    extreme_precip_days_errors_hist <- rbind(extreme_precip_days_errors_hist, errors_precip)
    
  },
  error = function(e) {
    # store the district code in error_districts if there's an error
    #temp_errors <<- c(temp_errors, code)
  })
  
  # update progress bar
  pb$tick()
  
} # end for loop

# export results to data folder
# write_csv(extreme_precip_days_errors_hist, here("data", "extreme_precip", "intermediate", "extreme_precip_days_errors_hist.csv"))
```

## Bind the results together

```{r}
# bind the errors and noerrors dataframes together and export to data folder
extreme_precip_days_full_hist <- rbind(extreme_precip_days_hist, extreme_precip_days_errors_hist)

#write_csv(extreme_precip_days_full_hist, here("data", "extreme_precip", "intermediate", "extreme_precip_days_full_hist.csv"))

# join back to school districts dataframe and select relevant columns
districts_precip_hist <- left_join(districts, extreme_precip_days_full_hist, by = "CDSCode") %>% 
  mutate(precip_days = count) %>% 
  select(CDSCode, CountyName, DistrictNa, DistrictTy, precip_days)

# export to data folder
#write_csv(districts_precip_hist, here("data", "hazard_summary", "individual_tables", "districts_precip_hist.csv"))
```

